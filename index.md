##### [RU](https://artkostm.github.io/cv/ru) [EN](https://artkostm.github.io/cv/)

## Artsiom Chuiko
>06.08.1994

>Georgia, Tbilisi

>[https://github.com/artkostm](https://github.com/artkostm)

>[artkostm@gmail.com](mailto:artkostm@gmail.com)

>English: Intermediate

I am a developer with more than 8 years of well-rounded experience in backend development, object-oriented design, microservices architecture, data processing, and functional programming. My skills span various fields of software engineering, including application, web, and system development. As a supportive and enthusiastic team player, I am dedicated to streamlining processes and efficiently resolving project issues. I always strive to build and improve reusable tools and solutions to achieve repeatable, high-quality results

Skill Highlights:
- Expertise in performance and scalability optimization.
- Fluent in Scala, Java and Python. Have expirience working with js/ts, haskell, purescript, c# and many more.
- Agile and Scrum methodologies.
- Advanced API design and implementation.
- Knowledge of SQL Server, MongoDB, PostgreDB, RabbitMQ, Kafka, Cassandra, Hadoop, and Spark.
- Experienced in Azure cloud services, have some knowledge of GCP, and AWS.
- Deep interest in data stack technologies, including data engineering, operations, and artificial intelligence
  
## Expirience

### **Sep - Dec, 2019** – Big Data Team 

**Project Roles**: Developer, Tech Lead

Developing Data Lake for a customer on Azure.

Led the development of a Data Lake on Azure, enhancing data pipelines, modeling, spearheaded the transition from classic Data Lake to Lake House architecture, focusing on data quality and governance.
- Project modularization;
- Implementation of data pipelines;
- Data modeling;
- Data mart, BI Reporting;
- Transition from classic Data Lake to Lake House;
- Data Quality anf Goverment;
- Implementing RAG using the latest Gen AI tech stack;
- Interviewing candidates;

**Tools:** _Azure, Databricks, Azure Data Factory, Azure Batch, Event Hub, Kafka, Spark, Log Analytics, Power BI, Sharepoint, Scala, Java, SQL, Python_

---

### **Jul - Aug, 2019** – Big Data Team 

**Project Roles**: Developer

New product analysis and predictions. 
Customer wanted high-profile Data Since work, but ended up putting the team into an archetecture/consultancy kind of way, so the project was effectively paused for lack of environment and data.

- Implementation of data pipelines;
- Data visualisation with Kibana dashboards;

**Tools:** _AWS, Glue, Elasticsearch, Kibana, Lambda, Java, Python_

---

### **Jan - Jul, 2019** – Big Data Team 

**Project Roles**: Developer

The project re-thought how our customer allocated inventory to its stores. By exploring algorithmic techniques, we developed demand forecasting algorithms, and applyed business rules to those forecasts to deliver improved store-level allocations that consider sales forecasts and regional effects + ecommerce allocation optimization.

Ensured data quality and optimized cloud infrastructure using Airflow, GCP, Hive, and Python
- Implementation of data pipelines;
- Data quality checks;
- Cloud infrastructure;

**Tools:** _Airflow, GCP, Hive, Terraform, Python, Pyspark, Pandas_

---

### **Oct, 2018 - Jan, 2019** – Big Data Team 

**Project Roles**: Developer

Implemented "discounts on the fly" processing over 1Tb of data within an hour using Spark structured streaming.
Conducted Spark and Kafka tuning and troubleshooting, ensuring optimal performance and reliability.

**Tools:** _Spark, Kafka, Scala, Sbt, S3, HDFS, Jenkins, Qubole_

---

### **Apr, 2017 - Oct, 2018** – Analyst tools team 

**Project Roles**: Developer

Implementation of web tools for the analysts, new case management platform

- Implementation of web tools for the analysts;
- Working on the new Case Management platform;
- Moving from .Net (aspx/classic asp) to Java + Angular 4;
- Participating in onboarding of new members;
- Working directly with customer developers from India during the last few months;

**Tools:** _Spring, Angular 4/5, Gradle, Mybatis, Rabbit, Mongo, Ms Sql, Karma, QueryDsl_

---

### **Jan, 2016 - Apr, 2017** – Fraud tools team 

**Project Roles**: Developer

Implementation of an auth service (REST) with Admin UI, disputes/debit memos autoimport

- Writing services to manage user roles/permissions;
- Working on services to autoimport disputes from different banks;
- Participating in communication with customer and in web app designing (REST api, ui mockups), database development, unit/integration/functional tests implementation;

**Tools:** _Spring, Mybatis, JQuery, Gradle, RetsAssured, JUnit, Mockito, Selenium, Ms Sql_

---

### **Feb, 2015 - Jan, 2016** – Fraud team

**Project Roles**: Developer

Implementation and support of sets of services to auto detect fraudulent transactions.

- Performing integration with external and internal web services;
- Developing applications for data processing using hive and hadooop java APIs;
- Supporting code base and monitoring environment (for example, Splunk, AppDynamics);
- Performing functional testing and dev unit testing;
- Participating in app design activities;

**Tools:** _Spring, Gradle, Ms Sql, MongoDB, Hadoop, JQuery, Splunk, Rabbit, Kibana, ElasticSearch, Jenkins, Stash, Guthub_

---

### **Sep, 2014 – Feb, 2015** – Data preparation to retrain fraud models

**Project Roles**: Developer, Tester, Ops

Using the tools below, we developed MapReduce jobs and hive-scripts for data preparation, so data scientists can retrain their fraud models.

**Partisipation:**
  * Writing hadoop jobs to prepare some data for model retraining;
  * Writing functional tests for the mr jobs and hive scripts;
  * Working on func tests design;
  
**Tools:** _Hadoop, Hive, Gradle, JUnit, Jsch, AngularJs_

---

## Certifications

Holder of numerous valid certifications in data engineering and operations: [View Certifications](https://credentials.databricks.com/profile/artkostm/wallet)

## Education

- Master of Technology (MTech), Engineering Psychology and Ergonomics, BSUIR – Faculty of Computer-Aided Design, 2016-2018
- Bachelor of Science (BS), Information Systems and Technologies, BSUIR – Faculty of Engineering and Economics, 2011-2016

## Outside of work

I have a keen interest in functional programming. In my free time, I love to play outdoor games, read books and blogs, and explore new technologies and features. I pay special attention to self-education. Below are some of my personal projects:

- Scala on android (free monad + redux). Tools: Macroid, Gradle, FreeS, Diode
- An android application with augmented reality support for the public transport schedule (Kotlin). Tools: Gradle, Anko, ObjectBox, Rx
- Web framework for the fast web app development. Tools: Netty, Akka (Java), Camel, Gradle, Level DB
- An application to aggregate different events in Minsk and for visiting them together (REST api +  android client app). Tools: Finatra, Slick, Sangria, Postgres, Circe, Dialog Flow, Swagger, Sbt, Heroku, Akka (Scala), Http4s, Doobie, Anko, Appolo, Gradle.
- YARN application framework. Tools: Hadoop, yarn clients, zio, cats, mu.
- Oracle Fusion HCM rest client. Tools: zio, sttp.
- A few PoCs related to data and web (see my github profile)
